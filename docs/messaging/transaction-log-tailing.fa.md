# خواندن لاگ تراکنش (Transaction Log Tailing)

## ۱. مقدمه

**خواندن لاگ تراکنش (Transaction Log Tailing)**، که با نام **Change Data Capture (CDC)** نیز شناخته می‌شود، تکنیکی است که لاگ تراکنش داخلی پایگاه داده را می‌خواند تا تغییرات commit شده را شناسایی کرده و به عنوان رویداد به یک واسطه پیام (message broker) منتشر کند. به جای تغییر کد برنامه برای ارسال رویدادها، CDC از مکانیزمی استفاده می‌کند که هر پایگاه داده رابطه‌ای برای دوام و تکرار (replication) از آن بهره می‌برد: **لاگ نوشتن پیش‌رو** (WAL در PostgreSQL) یا **لاگ باینری** (binlog در MySQL).

این الگو معمولاً در ترکیب با الگوی **Transactional Outbox** استفاده می‌شود. وقتی یک سرویس داده‌های تجاری و یک ردیف outbox را در یک تراکنش محلی می‌نویسد، یک رابط CDC ردیف جدید outbox را با خواندن لاگ تراکنش شناسایی کرده و آن را به یک واسطه پیام مانند [Apache Kafka](./rabbitmq-vs-kafka.fa.md) ارسال می‌کند.

```
+---------------------+       +-------------------+       +-----------------+
|    Application      |       | Transaction Log   |       | Message Broker  |
|                     |       | Tailer (CDC)      |       | (e.g. Kafka)    |
| +---------+------+  |       |                   |       |                 |
| | Business | Out- |  | WAL  |  Reads committed  | Pub   |  Downstream     |
| | Tables   | box  |--+----->|  rows from log    |------>|  Consumers      |
| |          | Table|  |      |                   |       |                 |
| +---------+------+  |       +-------------------+       +-----------------+
+---------------------+
```

خواندن لاگ تراکنش یک روش **غیرتهاجمی**، **کم‌تأخیر** و **قابل اعتماد** برای دریافت هر تغییر commit شده بدون polling پایگاه داده یا تغییر کوئری‌های برنامه فراهم می‌کند.

---

## ۲. زمینه و مسئله

در [معماری میکروسرویس‌ها](../architecture/microservices.fa.md)، سرویس‌ها اغلب نیاز دارند پایگاه داده خود را به‌روزرسانی کرده **و** سرویس‌های دیگر را از تغییرات مطلع کنند. یک رویکرد رایج الگوی Transactional Outbox است، جایی که سرویس یک رکورد رویداد را در جدول `outbox` به عنوان بخشی از همان تراکنش پایگاه داده که داده‌های تجاری را تغییر می‌دهد، می‌نویسد. این اتمی بودن بین تغییر وضعیت و رویداد را تضمین می‌کند.

با این حال، یک سؤال حیاتی باقی می‌ماند: **چگونه رویدادها را از جدول outbox خارج کرده و به واسطه پیام منتقل کنیم؟**

دو استراتژی اصلی وجود دارد:

1. **Polling Publisher** -- یک فرآیند پس‌زمینه به صورت دوره‌ای جدول outbox را برای ردیف‌های منتشر نشده کوئری می‌زند، آن‌ها را منتشر می‌کند و به عنوان ارسال شده علامت‌گذاری می‌کند.
2. **خواندن لاگ تراکنش (CDC)** -- یک رابط لاگ تراکنش پایگاه داده را می‌خواند تا ردیف‌های outbox تازه commit شده را شناسایی کرده و به واسطه پیام منتشر کند.

### مشکلات polling

| مشکل | توضیحات |
|------|---------|
| **تأخیر** | رویدادها به اندازه بازه polling تأخیر دارند (مثلاً ۱ تا ۵ ثانیه) |
| **بار پایگاه داده** | کوئری‌های مکرر `SELECT` حتی زمانی که رویداد جدیدی وجود ندارد به پایگاه داده فشار وارد می‌کنند |
| **مقیاس‌پذیری** | چندین poller نیاز به هماهنگی دارند تا از انتشار تکراری جلوگیری شود |
| **رویدادهای از دست رفته** | منطق نادرست polling یا شرایط رقابتی می‌تواند ردیف‌هایی را نادیده بگیرد |
| **سربار پاکسازی** | ردیف‌های poll شده باید حذف یا علامت‌گذاری شوند که بار نوشتن اضافه می‌کند |

خواندن لاگ تراکنش تمام این مشکلات را با خواندن رکورد داخلی تراکنش‌های commit شده پایگاه داده حل می‌کند.

---

## ۳. نیروها (Forces)

نیروهای زیر پذیرش خواندن لاگ تراکنش را نسبت به رویکردهای جایگزین هدایت می‌کنند:

- **تحویل تضمین‌شده** -- هر تراکنش commit شده در لاگ ظاهر می‌شود؛ هیچ چیز نادیده گرفته نمی‌شود.
- **تأخیر کم** -- تغییرات در عرض میلی‌ثانیه پس از commit دریافت می‌شوند، بسیار سریع‌تر از بازه‌های polling.
- **حداقل سربار روی پایگاه داده** -- خواندن لاگ یک عملیات سبک است که کوئری SQL روی جداول تجاری اجرا نمی‌کند.
- **بدون تغییر کد برنامه** -- رابط CDC در سطح پایگاه داده کار می‌کند؛ برنامه نیازی به ارسال صریح رویدادها ندارد.
- **معناشناسی exactly-once (با دقت)** -- در ترکیب با مصرف‌کنندگان idempotent یا حذف تکراری، این الگو می‌تواند عملاً پردازش exactly-once را حاصل کند.
- **تضمین ترتیب** -- لاگ تراکنش ترتیب دقیق commit را حفظ می‌کند و اطمینان می‌دهد رویدادها به ترتیب نوشته شدن منتشر می‌شوند.
- **پیچیدگی عملیاتی** -- زیرساخت CDC (رابط‌ها، Kafka Connect، رجیستری اسکیما) باید مستقر، نظارت و نگهداری شوند.
- **وابستگی به پایگاه داده** -- پیاده‌سازی به فرمت لاگ خاص موتور پایگاه داده وابسته است.

---

## ۴. راه‌حل

### نحوه کار لاگ تراکنش‌های پایگاه داده

هر پایگاه داده رابطه‌ای اصلی یک لاگ ترتیبی از تمام تغییرات commit شده را برای دوام و تکرار نگهداری می‌کند.

#### PostgreSQL: لاگ نوشتن پیش‌رو (WAL)

PostgreSQL هر تغییری را **قبل** از اعمال آن به فایل‌های داده در WAL می‌نویسد. این تضمین می‌کند که حتی اگر سرور از کار بیفتد، تراکنش‌های commit شده با بازپخش WAL قابل بازیابی هستند. PostgreSQL از طریق **اسلات‌های تکرار منطقی (logical replication slots)** WAL خود را در اختیار ابزارهای CDC قرار می‌دهد.

```
  Client Transaction
        |
        v
  +------------------+
  | Write to WAL     |  <-- Durable, sequential log
  +------------------+
        |
        v
  +------------------+
  | Apply to Tables  |  <-- Actual data pages updated
  +------------------+
        |
        v
  +------------------+
  | Logical Decoding |  <-- CDC reads changes from here
  +------------------+
```

#### MySQL: لاگ باینری (binlog)

binlog مایسکیوال تمام دستورات تغییر داده (در حالت statement-based) یا تغییرات واقعی ردیف (در حالت row-based) را ثبت می‌کند. ابزارهای CDC به عنوان یک رپلیکای MySQL متصل شده و جریان binlog را در زمان واقعی می‌خوانند.

```
  Client Transaction
        |
        v
  +------------------+
  | Write to binlog  |  <-- Row-based changes logged
  +------------------+
        |
        v
  +------------------+
  | Apply to InnoDB  |  <-- Storage engine updated
  +------------------+
        |
        v
  +------------------+
  | CDC Connector    |  <-- Reads binlog as a replica
  +------------------+
```

### معماری رابط CDC

رابط CDC بین پایگاه داده و واسطه پیام قرار می‌گیرد:

```
+------------------+     +---------------------+     +------------------+
|   Source DB      |     |   CDC Connector     |     |  Message Broker  |
|                  |     |   (e.g. Debezium)   |     |  (e.g. Kafka)   |
|  +-----------+   |     |                     |     |                  |
|  | outbox    |   | log |  1. Connect as      |     |  +-----------+  |
|  | table     |---+---->|     replica         |     |  | outbox    |  |
|  +-----------+   |     |  2. Read log stream |---->|  | topic     |  |
|  | orders    |   |     |  3. Filter tables   |     |  +-----------+  |
|  | customers |   |     |  4. Transform       |     |  +-----------+  |
|  +-----------+   |     |  5. Publish event   |     |  | orders    |  |
|                  |     |                     |     |  | topic     |  |
+------------------+     +---------------------+     +------------------+
```

### Debezium: استاندارد صنعتی

[Debezium](https://debezium.io/) پراستفاده‌ترین پلتفرم CDC متن‌باز است. این ابزار به عنوان مجموعه‌ای از رابط‌های منبع **Kafka Connect** اجرا می‌شود، یکی به ازای هر پایگاه داده پشتیبانی‌شده.

#### معماری Debezium

```
+------------+     +-------------------+     +------------------+     +----------------+
| PostgreSQL |     | Kafka Connect     |     | Apache Kafka     |     | Consumers      |
|            | WAL | +-----------+     |     |                  |     |                |
| outbox     |---->| | Debezium  |     | pub | +------------+  |     | Order Service  |
| table      |     | | Postgres  |-----+---->| | outbox     |--+---->| Notification   |
|            |     | | Connector |     |     | | events     |  |     | Analytics      |
+------------+     | +-----------+     |     | +------------+  |     +----------------+
                   +-------------------+     +------------------+

+------------+     +-------------------+            |
| MySQL      |     | Kafka Connect     |            |
|            | bin | +-----------+     |            |
| outbox     |---->| | Debezium  |     |     +------v---------+
| table      |     | | MySQL     |-----+---->| outbox events  |
|            |     | | Connector |     |     | topic          |
+------------+     | +-----------+     |     +----------------+
                   +-------------------+
```

**نحوه کار Debezium:**

1. **اتصال به پایگاه داده** به عنوان یک کلاینت تکرار (تکرار منطقی در PostgreSQL، خواننده binlog در MySQL).
2. **گرفتن اسنپ‌شات اولیه** از داده‌های موجود (اختیاری، قابل پیکربندی).
3. **جریان‌سازی تغییرات** در زمان واقعی هنگامی که به لاگ تراکنش commit می‌شوند.
4. **تبدیل تغییرات** به رویدادهای ساختاریافته (JSON یا Avro) شامل وضعیت ردیف قبل و بعد.
5. **انتشار رویدادها** به تاپیک‌های Kafka (به طور پیش‌فرض یک تاپیک به ازای هر جدول).
6. **پیگیری offset‌ها** در Kafka Connect تا بتواند پس از راه‌اندازی مجدد از جایی که متوقف شده ادامه دهد.

#### ساختار رویداد Debezium

یک رویداد تغییر معمول Debezium شامل موارد زیر است:

```json
{
  "schema": { ... },
  "payload": {
    "before": null,
    "after": {
      "id": "evt-001",
      "aggregate_type": "Order",
      "aggregate_id": "ord-123",
      "event_type": "OrderCreated",
      "payload": "{\"orderId\":\"ord-123\",\"amount\":99.99}",
      "created_at": 1706000000000
    },
    "source": {
      "version": "2.5.0",
      "connector": "mysql",
      "name": "inventory",
      "ts_ms": 1706000000000,
      "db": "ecommerce",
      "table": "outbox"
    },
    "op": "c",
    "ts_ms": 1706000000123
  }
}
```

| فیلد | توضیحات |
|------|---------|
| `before` | وضعیت ردیف قبل از تغییر (`null` برای درج‌ها) |
| `after` | وضعیت ردیف پس از تغییر |
| `source` | متادیتا درباره پایگاه داده، جدول، نسخه رابط |
| `op` | نوع عملیات: `c` = ایجاد، `u` = به‌روزرسانی، `d` = حذف، `r` = خواندن (اسنپ‌شات) |
| `ts_ms` | زمانی که Debezium رویداد را پردازش کرد |

### سایر ابزارهای CDC

| ابزار | پشتیبانی از پایگاه داده | مقصد | توضیحات |
|-------|------------------------|------|---------|
| **Debezium** | PostgreSQL، MySQL، MongoDB، SQL Server، Oracle، Cassandra | Kafka (از طریق Kafka Connect) | محبوب‌ترین، متن‌باز، پشتیبانی Red Hat |
| **Maxwell's Daemon** | فقط MySQL | Kafka، Kinesis، RabbitMQ، Redis | سبک، مختص MySQL |
| **AWS DMS** | اکثر DB‌های رابطه‌ای | Kinesis، S3، Redshift، Kafka | سرویس مدیریت‌شده، اکوسیستم AWS |
| **LinkedIn Databus** | Oracle، MySQL | مصرف‌کنندگان سفارشی | پیشگام CDC در مقیاس بزرگ، الهام‌بخش Debezium |
| **Striim** | طیف گسترده | Kafka، فضای ابری، پایگاه داده‌ها | تجاری، یکپارچه‌سازی بلادرنگ |
| **Airbyte** | طیف گسترده | مقاصد مختلف | متن‌باز ELT با حالت‌های CDC |
| **Google Datastream** | MySQL، PostgreSQL، Oracle | BigQuery، Cloud Storage | مدیریت‌شده، اکوسیستم GCP |

### مسیریاب رویداد Outbox (Debezium)

Debezium یک **مسیریاب رویداد Outbox** به صورت Single Message Transform (SMT) داخلی ارائه می‌دهد که الگوی Transactional Outbox را ساده‌تر می‌کند. به جای انتشار رویدادهای خام تغییر پایگاه داده، مسیریاب ستون‌های جدول outbox را استخراج کرده و بر اساس ستون `aggregate_type` به تاپیک‌های مناسب Kafka هدایت می‌کند.

```
Outbox Table Row:
+----------+----------------+--------------+---------------+------------------+
| id       | aggregate_type | aggregate_id | event_type    | payload          |
+----------+----------------+--------------+---------------+------------------+
| evt-001  | Order          | ord-123      | OrderCreated  | {"amount":99.99} |
+----------+----------------+--------------+---------------+------------------+

                        |
                        v  (Outbox Event Router SMT)

Kafka Topic: "outbox.event.Order"
Key: "ord-123"
Value: {"amount":99.99}
Headers: { "id": "evt-001", "eventType": "OrderCreated" }
```

---

## ۵. مثال

### نمونه کامل: MySQL binlog با Debezium و Kafka

یک سیستم تجارت الکترونیک را در نظر بگیرید که در آن سرویس سفارش، سفارش‌ها را ایجاد کرده و باید سرویس‌های پایین‌دستی را مطلع کند.

#### مرحله ۱: برنامه به صورت اتمی در جدول تجاری و outbox می‌نویسد

```sql
BEGIN;

INSERT INTO orders (id, customer_id, total, status)
VALUES ('ord-123', 'cust-456', 99.99, 'CREATED');

INSERT INTO outbox (id, aggregate_type, aggregate_id, event_type, payload, created_at)
VALUES (
    'evt-001',
    'Order',
    'ord-123',
    'OrderCreated',
    '{"orderId":"ord-123","customerId":"cust-456","total":99.99}',
    NOW()
);

COMMIT;
```

هر دو ردیف در یک تراکنش نوشته می‌شوند. اگر تراکنش شکست بخورد، هیچ‌کدام از ردیف‌ها نوشته نمی‌شوند.

#### مرحله ۲: MySQL در binlog می‌نویسد

MySQL تغییرات commit شده را در binlog ثبت می‌کند:

```
# at position 12345
#260206 10:30:00 server id 1  end_log_pos 12500
### INSERT INTO ecommerce.orders
### SET
###   @1='ord-123'
###   @2='cust-456'
###   @3=99.99
###   @4='CREATED'

### INSERT INTO ecommerce.outbox
### SET
###   @1='evt-001'
###   @2='Order'
###   @3='ord-123'
###   @4='OrderCreated'
###   @5='{"orderId":"ord-123","customerId":"cust-456","total":99.99}'
###   @6='2026-02-06 10:30:00'
```

#### مرحله ۳: Debezium بایلاگ را خوانده و به Kafka منتشر می‌کند

رابط MySQL Debezium که برای نظارت بر جدول `outbox` پیکربندی شده، ردیف جدید را شناسایی کرده و یک رویداد را به تاپیک Kafka با نام `outbox.event.Order` منتشر می‌کند.

**پیکربندی رابط Debezium (JSON):**

```json
{
  "name": "ecommerce-outbox-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql-primary",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "********",
    "database.server.id": "184054",
    "topic.prefix": "ecommerce",
    "database.include.list": "ecommerce",
    "table.include.list": "ecommerce.outbox",
    "transforms": "outbox",
    "transforms.outbox.type": "io.debezium.transforms.outbox.EventRouter",
    "transforms.outbox.table.field.event.id": "id",
    "transforms.outbox.table.field.event.key": "aggregate_id",
    "transforms.outbox.table.field.event.type": "event_type",
    "transforms.outbox.table.field.event.payload": "payload",
    "transforms.outbox.route.by.field": "aggregate_type",
    "transforms.outbox.route.topic.replacement": "outbox.event.${routedByValue}"
  }
}
```

#### مرحله ۴: سرویس‌های پایین‌دستی رویدادها را مصرف می‌کنند

```
+------------------+     +-----------+     +------------------+     +-------------------+
| Order Service    |     | MySQL     |     | Debezium +       |     | Kafka Topic:      |
|                  |     | binlog    |     | Kafka Connect    |     | outbox.event.Order|
| BEGIN;           |     |           |     |                  |     |                   |
|  INSERT orders   |---->| log entry |---->| read binlog      |---->| {"orderId":...}   |
|  INSERT outbox   |     |           |     | transform + pub  |     |                   |
| COMMIT;          |     |           |     |                  |     +--------+----------+
+------------------+     +-----------+     +------------------+              |
                                                                 +-----------+-----------+
                                                                 |           |           |
                                                           +-----v--+  +----v---+  +----v------+
                                                           |Notific-|  |Payment |  |Analytics  |
                                                           |ation   |  |Service |  |Service    |
                                                           |Service |  |        |  |           |
                                                           +--------+  +--------+  +-----------+
```

#### مرحله ۵: پاکسازی جدول outbox

پس از اینکه Debezium رویدادها را خوانده و منتشر کرد، ردیف‌های جدول outbox می‌توانند به صورت دوره‌ای حذف شوند تا از رشد بی‌حد جلوگیری شود:

```sql
-- Cron job or scheduled task
DELETE FROM outbox WHERE created_at < NOW() - INTERVAL 7 DAY;
```

از آنجا که Debezium لاگ را می‌خواند (نه خود جدول را)، حذف ردیف‌های قدیمی تأثیری بر تحویل رویداد ندارد.

---

## ۶. مزایا و معایب

### مزایا

| مزیت | توضیحات |
|------|---------|
| **تأخیر کم** | رویدادها در عرض میلی‌ثانیه پس از commit تراکنش دریافت می‌شوند، در مقایسه با ثانیه‌ها در polling |
| **بدون سربار polling** | کوئری‌های مکرر `SELECT` علیه جدول outbox حذف می‌شوند |
| **دریافت تمام تغییرات** | لاگ تراکنش منبع حقیقت است؛ هیچ تغییر commit شده‌ای از دست نمی‌رود |
| **بدون تغییر کد برنامه** | CDC در سطح پایگاه داده کار می‌کند؛ برنامه فقط در جداول می‌نویسد |
| **حفظ ترتیب** | رویدادها دقیقاً به ترتیبی که commit شده‌اند منتشر می‌شوند |
| **پشتیبانی از چندین جدول** | یک رابط واحد می‌تواند تغییرات را از چندین جدول همزمان دریافت کند |
| **اثبات‌شده در مقیاس** | توسط LinkedIn، Uber، Airbnb و اکثر معماری‌های مبتنی بر Kafka استفاده می‌شود |
| **جدا از برنامه** | رابط CDC به عنوان یک فرآیند مستقل اجرا می‌شود، مستقل از چرخه عمر برنامه |

### معایب

| عیب | توضیحات |
|-----|---------|
| **وابسته به پایگاه داده** | هر موتور پایگاه داده نیاز به رابط متفاوتی دارد (PostgreSQL، MySQL، MongoDB و غیره) |
| **پیچیدگی عملیاتی** | نیاز به استقرار و مدیریت Kafka Connect، رابط‌ها و احتمالاً رجیستری اسکیما |
| **نیاز به پیکربندی DB** | پایگاه داده باید برای تکرار منطقی (PostgreSQL) یا binlog مبتنی بر ردیف (MySQL) پیکربندی شود |
| **نگهداری لاگ** | اگر رابط CDC عقب بیفتد، پایگاه داده ممکن است ورودی‌های لاگ را قبل از مصرف حذف کند |
| **تکامل اسکیما** | تغییرات در اسکیمای جداول باید با دقت مدیریت شوند تا مصرف‌کنندگان پایین‌دستی دچار مشکل نشوند |
| **دشواری رفع اشکال** | ردیابی یک مشکل از برنامه از طریق لاگ، رابط و واسطه پیچیدگی اضافه می‌کند |
| **هزینه زیرساخت** | کلاستر Kafka Connect، رابط‌ها و نظارت به نیازهای زیرساختی اضافه می‌کنند |
| **سربار اسنپ‌شات** | اسنپ‌شات‌های اولیه از جداول بزرگ می‌توانند کند و منابع‌بر باشند |

### مقایسه خواندن لاگ تراکنش با Polling Publisher

| جنبه | خواندن لاگ تراکنش (CDC) | Polling Publisher |
|------|------------------------|-------------------|
| **تأخیر** | میلی‌ثانیه (تقریباً بلادرنگ) | ثانیه (بازه polling) |
| **بار پایگاه داده** | حداقل (لاگ را می‌خواند، نه جداول) | متوسط (کوئری‌های مکرر SELECT) |
| **قابلیت اطمینان** | بسیار بالا (لاگ منبع حقیقت است) | خوب (اما شرایط رقابتی ممکن است) |
| **پیاده‌سازی** | نیازمند زیرساخت (Kafka Connect، Debezium) | ساده (کد برنامه + زمان‌بند) |
| **ترتیب** | تضمین‌شده (ترتیب لاگ) | تقریبی (ترتیب کوئری) |
| **مقیاس‌پذیری** | عالی (خواننده واحد، مصرف‌کنندگان افقی) | نیاز به هماهنگی برای چندین poller |
| **وابستگی به DB** | محکم (فرمت لاگ خاص DB) | سست (SQL استاندارد) |
| **هزینه عملیاتی** | بالاتر (زیرساخت CDC) | پایین‌تر (فقط کد برنامه) |
| **بهترین برای** | سیستم‌های با توان بالا و تأخیر کم | سیستم‌های ساده، تیم‌های کوچک، نمونه‌های اولیه |

---

## ۷. الگوهای مرتبط

- **Transactional Outbox** -- خواندن لاگ تراکنش مکانیزم توصیه‌شده برای خواندن رویدادها از جدول outbox است. الگوی outbox اتمی بودن بین نوشتن تجاری و رویداد را تضمین می‌کند؛ CDC تحویل قابل اعتماد به واسطه پیام را مدیریت می‌کند.

- **Polling Publisher** -- جایگزین ساده‌تر خواندن لاگ تراکنش. به جای خواندن لاگ تراکنش، یک فرآیند پس‌زمینه جدول outbox را در بازه‌های منظم poll می‌کند. پیاده‌سازی آسان‌تر اما تأخیر، بار پایگاه داده و شرایط رقابتی احتمالی را معرفی می‌کند.

- **[معماری رویداد-محور](../event-driven/event-driven-architecture.fa.md)** -- خواندن لاگ تراکنش ارتباط رویداد-محور بین سرویس‌ها را با انتشار قابل اعتماد رویدادهای دامنه به واسطه پیام فعال می‌کند.

- **[CQRS](../data-patterns/cqrs.fa.md)** -- CDC می‌تواند برای همگام نگه داشتن مدل‌های خواندن با مدل نوشتن استفاده شود. تغییرات commit شده در پایگاه داده نوشتن از طریق لاگ تراکنش دریافت شده و برای به‌روزرسانی projection‌های سمت خواندن استفاده می‌شوند.

- **[الگوی Saga](../distributed-transactions/saga.fa.md)** -- الگوی Saga تراکنش‌های توزیع‌شده را از طریق رویدادها هماهنگ می‌کند. خواندن لاگ تراکنش اطمینان می‌دهد که این رویدادها به صورت قابل اعتماد از پایگاه داده هر سرویس منتشر می‌شوند.

- **Event Sourcing** -- در حالی که Event Sourcing رویدادها را به عنوان منبع اصلی حقیقت ذخیره می‌کند، CDC تغییرات وضعیت را از پایگاه‌های داده سنتی دریافت می‌کند. هر دو جریان‌های رویداد تولید می‌کنند، اما منابع آن‌ها متفاوت است.

- **[مقایسه RabbitMQ و Kafka](./rabbitmq-vs-kafka.fa.md)** -- Kafka رایج‌ترین مقصد برای خطوط لوله CDC است به دلیل معماری مبتنی بر لاگ و قابلیت بازپخش آن. RabbitMQ نیز می‌تواند مقصد باشد (مثلاً با Maxwell's Daemon) اما فاقد بازپخش بومی است.

- **[قضیه CAP](../fundamentals/cap-theorem.fa.md)** -- سیستم‌های مبتنی بر CDC در نهایت سازگار هستند. درک مصالحه‌های CAP هنگام طراحی سیستم‌هایی که سمت خواندن از سمت نوشتن عقب می‌افتد ضروری است.

---

## ۸. استفاده در دنیای واقعی

### LinkedIn

LinkedIn با **Databus** پیشگام CDC در مقیاس بزرگ بود. Databus یک سیستم متن‌باز Change Data Capture است. Databus برای تکرار تغییرات از پایگاه‌های داده Oracle و MySQL به ایندکس‌های جستجو، کش‌ها و رپلیکاهای خواندن پایین‌دستی ساخته شد. این ابزار الهام‌بخش بسیاری از ابزارهای مدرن CDC از جمله Debezium بود.

### Uber

Uber به طور گسترده از CDC برای پلتفرم داده خود استفاده می‌کند. تغییرات از پایگاه‌های داده عملیاتی MySQL از طریق binlog دریافت شده و به Apache Kafka جریان می‌یابند و تحلیل‌های بلادرنگ، ایندکس‌های جستجو (Elasticsearch) و انبارهای داده (Apache Hive/Spark) را تغذیه می‌کنند.

### Airbnb

Airbnb از CDC مبتنی بر Debezium برای همگام‌سازی داده بین پایگاه‌های داده اصلی و سرویس‌های پایین‌دستی استفاده کرد. این امر به‌روزرسانی بلادرنگ ایندکس‌های جستجو هنگام تغییر جزئیات آگهی‌ها را ممکن ساخت و جایگزین کارهای ETL دسته‌ای شد که ساعت‌ها تأخیر ایجاد می‌کردند.

### Shopify

Shopify از CDC برای تقویت خط لوله داده بلادرنگ خود استفاده می‌کند. تغییرات داده‌های فروشنده و سفارش از MySQL دریافت شده و به Kafka جریان می‌یابند که داشبوردهای بلادرنگ، تشخیص تقلب و همگام‌سازی موجودی را ممکن می‌سازند.

### Zalando

Zalando معماری رویداد-محور خود را حول CDC ساخت. آن‌ها از یک راه‌حل سفارشی به نام **Nakadi** (واسطه رویداد) در ترکیب با تکرار منطقی PostgreSQL برای انتشار رویدادهای دامنه استفاده می‌کنند که اتصال سست بین صدها میکروسرویس را ممکن می‌سازد.

### معماری رایج CDC در محیط تولید

```
+-------------------+     +-------------------+     +-------------------+
|  Service A        |     |  Service B        |     |  Service C        |
|  (PostgreSQL)     |     |  (MySQL)          |     |  (MongoDB)        |
+--------+----------+     +--------+----------+     +--------+----------+
         |                         |                         |
    WAL  |                  binlog |                 oplog   |
         v                         v                         v
+--------+----------+     +--------+----------+     +--------+----------+
| Debezium          |     | Debezium          |     | Debezium          |
| PG Connector      |     | MySQL Connector   |     | MongoDB Connector |
+--------+----------+     +--------+----------+     +--------+----------+
         |                         |                         |
         +------------+------------+------------+------------+
                      |                         |
                      v                         v
              +-------+--------+        +-------+--------+
              | Apache Kafka   |        | Schema Registry|
              | (Event Hub)    |        | (Avro/JSON)    |
              +-------+--------+        +----------------+
                      |
         +------------+------------+------------+
         |            |            |            |
         v            v            v            v
   +-----------+ +---------+ +---------+ +-----------+
   | Search    | | Analyt- | | Notif-  | | Data      |
   | Index     | | ics     | | ication | | Warehouse |
   | (Elastic) | | (Flink) | | Service | | (Redshift)|
   +-----------+ +---------+ +---------+ +-----------+
```

### ملاحظات پیکربندی و عملیاتی

| ملاحظه | توصیه |
|--------|-------|
| **نگهداری لاگ** | نگهداری لاگ پایگاه داده را به اندازه کافی بالا تنظیم کنید تا رابط CDC بتواند از خرابی بازیابی شود (مثلاً ۳ تا ۷ روز برای WAL PostgreSQL، انقضای binlog در MySQL) |
| **نظارت بر رابط** | تأخیر، توان عملیاتی و نرخ خطای رابط را از طریق JMX یا معیارهای Prometheus نظارت کنید |
| **تغییرات اسکیما** | از رجیستری اسکیما (Confluent Schema Registry) برای مدیریت تکامل اسکیما به صورت شفاف استفاده کنید |
| **اسنپ‌شات‌گیری** | برای راه‌اندازی اولیه، حالت اسنپ‌شات (`initial`، `schema_only`، `never`) را بر اساس حجم داده پیکربندی کنید |
| **مصرف‌کنندگان idempotent** | مصرف‌کنندگان را برای مدیریت رویدادهای تکراری طراحی کنید، زیرا تحویل at-least-once تضمین پیش‌فرض است |
| **پاکسازی outbox** | حذف دوره‌ای ردیف‌های قدیمی outbox را زمان‌بندی کنید تا از بزرگ شدن بیش از حد جدول جلوگیری شود |
| **دسترس‌پذیری بالا** | Kafka Connect را در حالت توزیع‌شده با چندین worker برای تحمل خطا اجرا کنید |
| **امنیت** | از SSL/TLS برای اتصالات پایگاه داده و ارتباط Kafka استفاده کنید؛ دسترسی کاربر CDC را به فقط خواندنی روی لاگ محدود کنید |

---

## ۹. خلاصه

خواندن لاگ تراکنش (CDC) رویکرد **آماده تولید** برای انتشار قابل اعتماد تغییرات پایگاه داده به عنوان رویداد است. این روش تأخیر و سربار polling را حذف می‌کند، تضمین می‌کند هیچ تغییر commit شده‌ای از دست نمی‌رود و ترتیب دقیق تراکنش‌ها را حفظ می‌کند.

**نکات کلیدی:**

1. **CDC لاگ تراکنش خود پایگاه داده** (WAL، binlog، oplog) را برای شناسایی تغییرات می‌خواند -- جداول برنامه را poll نمی‌کند.
2. **Debezium** استاندارد عملی پلتفرم CDC است که به عنوان رابط‌های منبع Kafka Connect اجرا می‌شود.
3. **در ترکیب با الگوی Transactional Outbox**، CDC مکانیزمی قوی برای ارتباط رویداد-محور با سازگاری نهایی بین [میکروسرویس‌ها](../architecture/microservices.fa.md) فراهم می‌کند.
4. **مصالحه**: پیچیدگی عملیاتی زیرساخت CDC در مقابل سادگی polling. برای تیم‌های کوچک یا نمونه‌های اولیه، polling ممکن است کافی باشد. برای سیستم‌های تولیدی در مقیاس، CDC رویکرد توصیه‌شده است.
5. **پذیرش در دنیای واقعی** توسط LinkedIn، Uber، Airbnb، Shopify و اکثر سازمان‌هایی که از معماری‌های مبتنی بر Kafka استفاده می‌کنند، قابلیت اطمینان این الگو را تأیید می‌کند.

```
Choose your approach:

+---------------------------+     +---------------------------+
|   Simple / Small Scale    |     |   Production / At Scale   |
|                           |     |                           |
|   Polling Publisher       |     |   Transaction Log Tailing |
|                           |     |                           |
|   - Cron / scheduler      |     |   - Debezium / CDC        |
|   - SELECT from outbox    |     |   - Read WAL / binlog     |
|   - Mark as published     |     |   - Publish to Kafka      |
|   - Simple to implement   |     |   - Low latency           |
|   - Higher latency        |     |   - No DB load            |
|   - DB load from polling  |     |   - Operationally complex |
+---------------------------+     +---------------------------+
```

---

**همچنین ببینید:**
- [معماری رویداد-محور](../event-driven/event-driven-architecture.fa.md)
- [CQRS](../data-patterns/cqrs.fa.md)
- [الگوی Saga](../distributed-transactions/saga.fa.md)
- [مقایسه RabbitMQ و Kafka](./rabbitmq-vs-kafka.fa.md)
- [قضیه CAP](../fundamentals/cap-theorem.fa.md)
- [معماری میکروسرویس‌ها](../architecture/microservices.fa.md)
