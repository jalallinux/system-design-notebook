# فراخوانی از راه دور (RPI - Remote Procedure Invocation)

## 1. مقدمه

فراخوانی از راه دور (RPI) یک الگوی ارتباط همزمان بین سرویس‌ها است که در آن کلاینت یک درخواست به یک سرویس از راه دور ارسال می‌کند و **تا دریافت پاسخ مسدود می‌شود** (درخواست/پاسخ). این یکی از قدیمی‌ترین و پرکاربردترین مکانیزم‌های ارتباطی در سیستم‌های توزیع‌شده است که به مفهوم اصلی Remote Procedure Call (RPC) پیشنهاد شده توسط Bruce Jay Nelson در سال 1981 بازمی‌گردد.

**چرا اهمیت دارد:**

در [معماری میکروسرویس‌ها](../architecture/microservices.md)، سرویس‌ها باید برای انجام عملیات تجاری با یکدیگر ارتباط برقرار کنند. RPI ساده‌ترین مدل ذهنی را برای این ارتباط فراهم می‌کند: یک سرویس، سرویس دیگری را درست مانند فراخوانی یک تابع محلی صدا می‌زند، با این تفاوت که فراخوانی از طریق شبکه انجام می‌شود. این آشنایی باعث می‌شود RPI انتخاب پیش‌فرض بسیاری از تیم‌هایی باشد که سیستم‌های توزیع‌شده می‌سازند.

**اصل اساسی:**

فراخوانی‌کننده یک رویه را روی سرویس از راه دور فراخوانی می‌کند، درخواست را سریال‌سازی می‌کند، آن را از طریق شبکه ارسال می‌کند و منتظر می‌ماند تا سرویس از راه دور آن را دی‌سریال‌سازی، پردازش و پاسخ سریال‌سازی شده را برگرداند. از دیدگاه فراخوانی‌کننده، تعامل شبیه یک فراخوانی تابع معمولی به نظر می‌رسد.

```
┌──────────────┐                          ┌──────────────┐
│              │   1. Request (blocked)    │              │
│    Client    │─────────────────────────▶│   Service    │
│   Service    │                          │   (Remote)   │
│              │◀─────────────────────────│              │
│              │   2. Response (unblock)   │              │
└──────────────┘                          └──────────────┘
```

**RPI در مقابل پیام‌رسانی:**

در حالی که RPI همزمان و مبتنی بر درخواست/پاسخ است، [پیام‌رسانی](../messaging/rabbitmq-vs-kafka.md) یک جایگزین ناهمزمان است که در آن فراخوانی‌کننده یک پیام ارسال می‌کند و منتظر پاسخ فوری نمی‌ماند. هر دو الگو جایگاه خود را دارند؛ RPI زمانی که به پاسخ فوری نیاز دارید عالی است، در حالی که پیام‌رسانی در جداسازی و تاب‌آوری برتری دارد.

---

## 2. زمینه و مسئله

### چالش ارتباط میکروسرویس‌ها

وقتی یک مونولیت را به [میکروسرویس‌ها](../architecture/microservices.md) تجزیه می‌کنید، آنچه قبلاً فراخوانی‌های متد درون-فرآیندی بود به فراخوانی‌های شبکه‌ای بین سرویس‌ها تبدیل می‌شود. هر سرویس مالک داده‌ها و منطق خود است، بنابراین سرویس‌ها باید از طریق شبکه همکاری کنند تا یک عملیات تجاری کامل را ترکیب کنند.

```
Monolith (single process)          Microservices (distributed)
┌─────────────────────────┐        ┌──────────┐   ┌──────────┐
│  Order  │  Payment      │        │  Order   │──▶│ Payment  │
│  Module │  Module       │   ──▶  │  Service │   │ Service  │
│─────────│───────────────│        └──────────┘   └──────────┘
│  Inventory │ Shipping   │        ┌──────────┐   ┌──────────┐
│  Module    │ Module     │        │Inventory │   │ Shipping │
└─────────────────────────┘        │ Service  │   │ Service  │
                                   └──────────┘   └──────────┘
  In-process calls (fast)          Network calls (latency, failures)
```

### مسئله

**سرویس‌ها در معماری میکروسرویس‌ها چگونه باید ارتباط برقرار کنند وقتی پاسخ فوری مورد نیاز است؟**

یک جریان تسویه حساب تجارت الکترونیک را در نظر بگیرید:

1. **سرویس سفارش** باید با فراخوانی **سرویس موجودی** بررسی کند که آیا اقلام در انبار هستند.
2. سپس باید با فراخوانی **سرویس پرداخت** مشتری را شارژ کند.
3. قبل از تأیید سفارش به نتیجه پرداخت نیاز دارد.

هر یک از این مراحل به پاسخ فوری نیاز دارد. سرویس سفارش نمی‌تواند بدون نتیجه مرحله 1 به مرحله 2 برود و بدون نتیجه مرحله 2 نمی‌تواند سفارش را تأیید کند. این یک تناسب طبیعی برای ارتباط همزمان درخواست/پاسخ است.

---

## 3. نیروها

هنگام تصمیم‌گیری درباره استفاده از RPI، نیروهای (مصالحه‌های) زیر وارد عمل می‌شوند:

| نیرو | به نفع RPI | علیه RPI |
|------|------------|----------|
| **سادگی** | مدل آشنای درخواست/پاسخ؛ آسان برای استدلال | پیچیدگی فراخوانی‌های شبکه‌ای را پشت یک رابط ساده پنهان می‌کند |
| **فوریت** | فراخوانی‌کننده فوراً پاسخ دریافت می‌کند | فراخوانی‌کننده در حین انتظار مسدود است |
| **تجربه توسعه‌دهنده** | شبیه فراخوانی تابع محلی؛ ابزارهای غنی | می‌تواند توسعه‌دهندگان را از نادیده‌گرفتن تأخیر و حالات شکست گمراه کند |
| **وابستگی زمانی** | N/A | هر دو سرویس باید همزمان در حال اجرا باشند |
| **دسترس‌پذیری** | N/A | دسترس‌پذیری کلی حاصل‌ضرب دسترس‌پذیری‌های فردی سرویس‌ها است |
| **شکست‌های آبشاری** | N/A | یک سرویس کند یا خراب می‌تواند به بالا آبشار شود |
| **مقیاس‌پذیری** | توازن بار ساده بین نمونه‌ها | فراخوانی‌های همزمان thread/connection مصرف می‌کنند |
| **اشکال‌زدایی** | ردیابی درخواست/پاسخ آسان است | زنجیره‌های طولانی فراخوانی همزمان در مقیاس سخت هستند |

**تأثیر بر دسترس‌پذیری:**

اگر سرویس A سرویس B را از طریق RPI فراخوانی کند و هر کدام به طور مستقل 99.5% دسترس‌پذیری داشته باشند، دسترس‌پذیری ترکیبی برای آن عملیات تقریباً به 99.5% x 99.5% = 99.0% کاهش می‌یابد. با هر پرش همزمان اضافی، دسترس‌پذیری بیشتر کاهش می‌یابد. این یکی از قوی‌ترین استدلال‌ها برای در نظر گرفتن [پیام‌رسانی](../messaging/rabbitmq-vs-kafka.md) ناهمزمان در صورت امکان است.

---

## 4. راه‌حل

### استفاده از پروتکل درخواست/پاسخ

راه‌حل اتخاذ یک **پروتکل درخواست/پاسخ** است که در آن کلاینت (سرویس فراخوانی‌کننده) یک رویه از راه دور را روی سرور (سرویس هدف) فراخوانی می‌کند و تا زمانی که سرور پاسخ برگرداند مسدود می‌شود.

```
┌───────────┐                                      ┌───────────┐
│  Client   │                                      │  Server   │
│  Service  │                                      │  Service  │
└─────┬─────┘                                      └─────┬─────┘
      │                                                  │
      │  1. Serialize request                            │
      │  2. Send over network ──────────────────────────▶│
      │                                                  │  3. Deserialize
      │                                                  │  4. Process
      │                                                  │  5. Serialize response
      │◀────────────────────────── 6. Send response ─────│
      │  7. Deserialize response                         │
      │  8. Continue processing                          │
      │                                                  │
```

### فناوری‌های RPI

چندین فناوری محبوب برای پیاده‌سازی RPI وجود دارد. رایج‌ترین آن‌ها عبارتند از:

#### 4.1 REST روی HTTP

REST (انتقال وضعیت نمایندگی) یک سبک معماری منبع‌محور است که از فعل‌های استاندارد HTTP (GET، POST، PUT، DELETE) و معمولاً JSON برای سریال‌سازی استفاده می‌کند.

```
Client                                            Server
  │                                                  │
  │  GET /api/products/42  HTTP/1.1                  │
  │  Accept: application/json                        │
  │─────────────────────────────────────────────────▶│
  │                                                  │
  │  HTTP/1.1 200 OK                                 │
  │  Content-Type: application/json                  │
  │  {"id": 42, "name": "Widget", "price": 9.99}    │
  │◀─────────────────────────────────────────────────│
  │                                                  │
```

**ویژگی‌ها:**
- منبع‌محور (اسم‌ها، نه فعل‌ها)
- بار داده JSON قابل خواندن توسط انسان
- بدون حالت (stateless)؛ هر درخواست تمام زمینه لازم را حمل می‌کند
- استفاده از کش HTTP (ETags، Cache-Control)
- پشتیبانی گسترده مرورگر و ابزار (curl، Postman، Swagger/OpenAPI)
- اکوسیستم بالغ با middleware گسترده

#### 4.2 gRPC (Protocol Buffers)

gRPC یک چارچوب RPC منبع‌باز و با عملکرد بالا است که در اصل توسط Google توسعه یافته است. از Protocol Buffers (protobuf) برای سریال‌سازی و HTTP/2 به عنوان لایه انتقال استفاده می‌کند.

```
Client                                            Server
  │                                                  │
  │  HTTP/2 POST /payment.PaymentService/Charge      │
  │  Content-Type: application/grpc+proto             │
  │  [binary protobuf payload]                        │
  │─────────────────────────────────────────────────▶│
  │                                                  │
  │  HTTP/2 200 OK                                   │
  │  Content-Type: application/grpc+proto             │
  │  [binary protobuf response]                       │
  │◀─────────────────────────────────────────────────│
  │                                                  │
```

**ویژگی‌ها:**
- سریال‌سازی باینری Protocol Buffers (کوچک‌تر، سریع‌تر)
- انتقال HTTP/2 (مالتی‌پلکسینگ، فشرده‌سازی هدر، استریمینگ)
- قراردادهای با نوع قوی تعریف شده در فایل‌های `.proto`
- تولید خودکار کد برای بیش از 10 زبان
- پشتیبانی از چهار الگوی ارتباطی: یکانه (unary)، استریمینگ سرور، استریمینگ کلاینت، دوطرفه
- مهلت‌ها (deadlines)، لغو و توازن بار داخلی

#### 4.3 سایر فناوری‌های RPI

- **Apache Thrift:** چارچوب RPC توسعه‌یافته توسط Facebook با IDL و پروتکل باینری خاص خود. مشابه gRPC اما قبل از آن ایجاد شده است.
- **GraphQL:** یک زبان پرس‌وجو برای APIها که در آن کلاینت دقیقاً مشخص می‌کند چه داده‌ای نیاز دارد. over-fetching و under-fetching را کاهش می‌دهد اما پیچیدگی سمت سرور اضافه می‌کند.

### 4.4 مقایسه REST در مقابل gRPC

| جنبه | REST (HTTP/JSON) | gRPC (HTTP/2 + Protobuf) |
|------|-------------------|--------------------------|
| **سریال‌سازی** | JSON (متنی، قابل خواندن توسط انسان) | Protocol Buffers (باینری، فشرده) |
| **عملکرد** | کندتر (تجزیه متن، بار داده بزرگ‌تر) | سریع‌تر (باینری، بار داده کوچک‌تر) |
| **قرارداد** | OpenAPI/Swagger (اختیاری) | فایل‌های `.proto` (اجباری، سختگیرانه) |
| **تولید کد** | اختیاری (ابزارهای مختلف) | داخلی (کامپایلر protoc) |
| **پشتیبانی مرورگر** | بومی (fetch، XMLHttpRequest) | نیاز به پروکسی grpc-web |
| **استریمینگ** | محدود (SSE، WebSocket جداگانه) | بومی (4 حالت استریمینگ) |
| **کش** | کش HTTP داخلی | بدون کش HTTP بومی |
| **ابزار** | curl، Postman، DevTools مرورگر | grpcurl، BloomRPC، Evans |
| **منحنی یادگیری** | کم | متوسط |
| **بهترین برای** | APIهای عمومی، فرانت‌اند وب | فراخوانی‌های داخلی سرویس به سرویس |
| **اشکال‌زدایی** | آسان (JSON خوانا است) | سخت‌تر (بار داده باینری) |
| **سازگاری رو به عقب** | نسخه‌بندی دستی (/v1، /v2) | داخلی protobuf (شماره فیلدها) |

**چه زمانی REST را انتخاب کنید:**
- APIهای عمومی مصرف‌شده توسط اشخاص ثالث
- کلاینت‌های مرورگر وب
- تیم‌هایی که تازه با میکروسرویس‌ها شروع کرده‌اند
- وقتی خوانایی بار داده توسط انسان مهم است
- وقتی کش HTTP مفید است

**چه زمانی gRPC را انتخاب کنید:**
- ارتباط داخلی سرویس به سرویس با عملکرد بالا
- محیط‌های چندزبانه که نیاز به تولید کد دارند
- نیازمندی‌های استریمینگ داده (به‌روزرسانی‌های بلادرنگ)
- وقتی اجرای سختگیرانه قرارداد مطلوب است
- محیط‌های با محدودیت پهنای باند (موبایل، IoT)

### 4.5 کشف سرویس

قبل از اینکه کلاینت بتواند یک رویه از راه دور را فراخوانی کند، باید بداند سرویس هدف **کجا** در حال اجرا است. در یک محیط میکروسرویس‌های پویا، نمونه‌های سرویس می‌آیند و می‌روند. کشف سرویس این مشکل را حل می‌کند.

```
              Client-Side Discovery                    Server-Side Discovery

┌────────┐  1.Query  ┌──────────┐              ┌────────┐        ┌────────────┐
│ Client │─────────▶│ Service  │              │ Client │───────▶│   Load     │
│Service │           │ Registry │              │Service │        │  Balancer  │
└───┬────┘          └──────────┘              └────────┘        └──────┬─────┘
    │  2.Get instances                                                │
    │  [svc-b:8080,                                          ┌───────┼───────┐
    │   svc-b:8081]                                          ▼       ▼       ▼
    │                                                    ┌──────┐┌──────┐┌──────┐
    │  3.Call directly                                   │Svc-B ││Svc-B ││Svc-B │
    ├──────────────▶ svc-b:8080                          │:8080 ││:8081 ││:8082 │
    │                                                    └──────┘└──────┘└──────┘
```

**کشف سمت کلاینت:**
- کلاینت از رجیستری سرویس (مانند Consul، Eureka، etcd) پرس‌وجو می‌کند
- کلاینت یک نمونه را انتخاب می‌کند (round-robin، تصادفی، کمترین اتصال)
- کلاینت مستقیماً نمونه را فراخوانی می‌کند
- مزایا: بدون پرش شبکه اضافی؛ کلاینت می‌تواند مسیریابی هوشمند اعمال کند
- معایب: کلاینت نیاز به منطق کشف دارد؛ کتابخانه‌های مختص زبان

**کشف سمت سرور:**
- کلاینت درخواست را به load balancer یا [API Gateway](../architecture/api-gateway.md) ارسال می‌کند
- load balancer از رجیستری پرس‌وجو کرده و به یک نمونه ارسال می‌کند
- مزایا: کلاینت ساده‌تر؛ منطق کشف متمرکز
- معایب: پرش شبکه اضافی؛ load balancer یک گلوگاه بالقوه است

### 4.6 مدیریت شکست‌ها

از آنجا که RPI از طریق شبکه انجام می‌شود، شکست‌ها اجتناب‌ناپذیر هستند. یک پیاده‌سازی قوی RPI باید موارد زیر را مدیریت کند:

**مهلت‌ها (Timeouts):**
- حداکثر زمان انتظار برای پاسخ را تنظیم کنید
- از مسدود شدن نامحدود threadها جلوگیری می‌کند
- مقادیر مهلت را بر اساس SLA سرویس هدف انتخاب کنید

**تلاش مجدد با Backoff نمایی:**
- شکست‌های گذرا (اختلالات شبکه، اضافه بار موقت) را مجدداً تلاش کنید
- از backoff نمایی با jitter برای جلوگیری از thundering herd استفاده کنید
- حداکثر تعداد تلاش‌های مجدد را تنظیم کنید

**[الگوی Circuit Breaker](../resilience/circuit-breaker.md):**
- نرخ شکست برای هر سرویس پایین‌دست را نظارت کنید
- مدار را وقتی شکست‌ها از آستانه تجاوز می‌کنند باز کنید
- به جای هدر دادن منابع روی فراخوانی‌های محکوم به شکست، سریع خراب شوید
- به طور دوره‌ای بازیابی را آزمایش کنید (حالت نیمه‌باز)

```
RPI Failure Handling Pipeline:

Request
  │
  ▼
┌──────────────────┐
│  Circuit Breaker │──── Open? ───▶ Fail Fast / Fallback
│  Check           │
└────────┬─────────┘
         │ Closed
         ▼
┌──────────────────┐
│  Send Request    │
│  (with timeout)  │
└────────┬─────────┘
         │
    ┌────┴────┐
    │         │
  Success   Failure
    │         │
    ▼         ▼
  Return   ┌──────────────────┐
  Result   │  Retry?          │
           │  (max 3 attempts │
           │   with backoff)  │
           └────────┬─────────┘
                    │
               ┌────┴────┐
               │         │
           Retry OK   Max retries
               │      exceeded
               ▼         │
            Return       ▼
            Result    Report failure
                      to Circuit Breaker
```

---

## 5. مثال

### سرویس سفارش سرویس پرداخت را از طریق gRPC فراخوانی می‌کند

یک سیستم تجارت الکترونیک میکروسرویسی را در نظر بگیرید که **سرویس سفارش** باید مشتری را در حین تسویه حساب شارژ کند. از gRPC برای پردازش همزمان پرداخت استفاده می‌کند.

**مرحله 1: تعریف قرارداد (فایل .proto)**

```protobuf
syntax = "proto3";

package payment;

service PaymentService {
  rpc Charge (ChargeRequest) returns (ChargeResponse);
}

message ChargeRequest {
  string order_id = 1;
  string customer_id = 2;
  double amount = 3;
  string currency = 4;
  string payment_method_token = 5;
}

message ChargeResponse {
  string transaction_id = 1;
  PaymentStatus status = 2;
  string message = 3;
}

enum PaymentStatus {
  PAYMENT_SUCCESS = 0;
  PAYMENT_DECLINED = 1;
  PAYMENT_FAILED = 2;
}
```

**مرحله 2: پیاده‌سازی سرور (سرویس پرداخت)**

```python
class PaymentServicer(payment_pb2_grpc.PaymentServiceServicer):

    def Charge(self, request, context):
        # Validate request
        if request.amount <= 0:
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details("Amount must be positive")
            return payment_pb2.ChargeResponse()

        # Process payment with external gateway
        try:
            result = payment_gateway.charge(
                customer_id=request.customer_id,
                amount=request.amount,
                currency=request.currency,
                token=request.payment_method_token
            )
            return payment_pb2.ChargeResponse(
                transaction_id=result.txn_id,
                status=payment_pb2.PAYMENT_SUCCESS,
                message="Payment processed successfully"
            )
        except PaymentDeclinedException as e:
            return payment_pb2.ChargeResponse(
                status=payment_pb2.PAYMENT_DECLINED,
                message=str(e)
            )
```

**مرحله 3: پیاده‌سازی کلاینت (سرویس سفارش)**

```python
class OrderService:

    def __init__(self):
        channel = grpc.insecure_channel('payment-service:50051')
        self.payment_stub = payment_pb2_grpc.PaymentServiceStub(channel)

    def checkout(self, order):
        # Build the charge request
        charge_request = payment_pb2.ChargeRequest(
            order_id=order.id,
            customer_id=order.customer_id,
            amount=order.total,
            currency="USD",
            payment_method_token=order.payment_token
        )

        try:
            # Synchronous gRPC call - blocks until response
            response = self.payment_stub.Charge(
                charge_request,
                timeout=5.0  # 5-second deadline
            )

            if response.status == payment_pb2.PAYMENT_SUCCESS:
                order.mark_paid(response.transaction_id)
                return OrderResult.success(order)
            else:
                return OrderResult.payment_failed(response.message)

        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.DEADLINE_EXCEEDED:
                # Handle timeout - maybe queue for retry
                return OrderResult.timeout()
            raise
```

**نمودار توالی:**

```
┌────────┐         ┌──────────┐         ┌──────────┐         ┌──────────┐
│  User  │         │  Order   │         │ Payment  │         │ External │
│Browser │         │ Service  │         │ Service  │         │ Gateway  │
└───┬────┘         └────┬─────┘         └────┬─────┘         └────┬─────┘
    │                    │                    │                    │
    │ POST /checkout     │                    │                    │
    ├───────────────────▶│                    │                    │
    │                    │                    │                    │
    │                    │  gRPC Charge()     │                    │
    │                    ├───────────────────▶│                    │
    │                    │  (blocked)         │                    │
    │                    │                    │  HTTP POST /charge │
    │                    │                    ├───────────────────▶│
    │                    │                    │                    │
    │                    │                    │  200 OK            │
    │                    │                    │◀───────────────────┤
    │                    │                    │                    │
    │                    │  ChargeResponse    │                    │
    │                    │◀───────────────────┤                    │
    │                    │  (unblocked)       │                    │
    │                    │                    │                    │
    │  201 Order Created │                    │                    │
    │◀───────────────────┤                    │                    │
    │                    │                    │                    │
```

---

## 6. مزایا و معایب

### مزایا

**مدل ذهنی ساده:**
RPI الگوی آشنای فراخوانی تابع را تقلید می‌کند. توسعه‌دهندگان درخواست/پاسخ را به صورت شهودی درک می‌کنند که باعث سرعت بیشتر در آنبردینگ و خوانایی آسان‌تر کد می‌شود.

**اشکال‌زدایی و ردیابی آسان:**
هر فراخوانی یک درخواست و پاسخ واضح دارد. ابزارهای ردیابی توزیع‌شده (Jaeger، Zipkin) می‌توانند زنجیره درخواست را از ابتدا تا انتها دنبال کنند. RPI مبتنی بر HTTP را می‌توان با ابزارهای استاندارد مانند curl و DevTools مرورگر بررسی کرد.

**پاسخ فوری:**
فراخوانی‌کننده نتیجه را فوراً می‌داند. این برای عملیاتی که کاربر منتظر است (تسویه حساب، ورود، جستجو) ضروری است.

**اکوسیستم غنی:**
REST دهه‌ها ابزار دارد (OpenAPI، Postman، API gatewayها). gRPC تولید کد قوی و ایمنی نوع دارد. هر دو کتابخانه‌های بالغ در هر زبان اصلی دارند.

**مدیریت خطای آشنا:**
کدهای وضعیت HTTP (REST) و کدهای وضعیت gRPC یک واژگان استاندارد برای موفقیت، خطاهای کلاینت، خطاهای سرور، مهلت‌ها و موارد دیگر فراهم می‌کنند.

### معایب

**وابستگی زمانی:**
هم کلاینت و هم سرور باید همزمان در حال اجرا باشند. اگر سرور خاموش باشد، عملیات کلاینت شکست می‌خورد. این در تضاد با پیام‌رسانی است، جایی که واسطه پیام فرستنده و گیرنده را در زمان جدا می‌کند.

**شکست‌های آبشاری:**
یک سرویس کند یا خراب پایین‌دست می‌تواند باعث مسدود شدن فراخوانی‌کننده شود و threadها و اتصالات آن را تمام کند. بدون [circuit breakerها](../resilience/circuit-breaker.md)، این می‌تواند در کل سیستم آبشار شود.

**کاهش دسترس‌پذیری:**
همان‌طور که در بخش 3 ذکر شد، دسترس‌پذیری ترکیبی یک زنجیره فراخوانی همزمان حاصل‌ضرب دسترس‌پذیری هر سرویس است. زنجیره‌ای از پنج سرویس هر کدام با 99.5% فقط ~97.5% دسترس‌پذیری دارد.

```
Availability of synchronous chain:

Service A ──▶ Service B ──▶ Service C ──▶ Service D

Combined = 99.5% x 99.5% x 99.5% x 99.5% = ~98.0%

vs. Asynchronous (messaging):

Service A ──▶ Message Broker ──▶ Service B (processes later)

Service A availability is independent of Service B
```

**مصرف Thread/Connection:**
هر فراخوانی RPI در حال انجام یک thread یا اتصال در فراخوانی‌کننده مصرف می‌کند. تحت بار بالا، این همزمانی را محدود می‌کند. چارچوب‌های reactive یا async (مانند Spring WebFlux، asyncio) می‌توانند این را کاهش دهند اما پیچیدگی اضافه می‌کنند.

**وابستگی محکم رابط:**
هم کلاینت و هم سرور باید بر سر رابط (قرارداد API) توافق داشته باشند. تغییرات در API نیاز به هماهنگی دارد. شماره‌گذاری فیلد protobuf در gRPC به سازگاری رو به عقب کمک می‌کند، اما تغییرات شکننده همچنان نیاز به هماهنگی استقرار دارند.

### چه زمانی از RPI در مقابل پیام‌رسانی استفاده کنیم

| سناریو | پیشنهاد | دلیل |
|---------|---------|-------|
| کاربر منتظر نتیجه (تسویه حساب، جستجو) | **RPI** | پاسخ فوری لازم است |
| عملیات ارسال و فراموش (ارسال ایمیل، ثبت رویداد) | **پیام‌رسانی** | پاسخ لازم نیست؛ جداسازی |
| جریان‌های کاری طولانی‌مدت (تکمیل سفارش) | **پیام‌رسانی** | مراحل می‌توانند ناهمزمان انجام شوند |
| پرس‌وجوهای بلادرنگ (بررسی موجودی، دریافت قیمت) | **RPI** | پاسخ فوری و به‌روز لازم است |
| اطلاع‌رسانی رویداد (سفارش ثبت شد، کاربر ثبت‌نام کرد) | **پیام‌رسانی** | مصرف‌کنندگان متعدد، اتصال سست |
| نیاز به دسترس‌پذیری بالا | **پیام‌رسانی** | از وابستگی زمانی اجتناب می‌کند |
| عملیات ساده CRUD | **RPI** | ساده، قابل درک |
| یکپارچه‌سازی بین تیم/سازمان | **RPI (REST)** | جهانی، خود-مستندساز |

---

## 7. الگوهای مرتبط

- **[پیام‌رسانی / ارتباط ناهمزمان](../messaging/rabbitmq-vs-kafka.md):** جایگزین ناهمزمان RPI. به جای مسدود شدن برای پاسخ، فراخوانی‌کننده یک پیام به واسطه (RabbitMQ، Kafka) ارسال می‌کند و ادامه می‌دهد. گیرنده پیام را به طور مستقل پردازش می‌کند. از پیام‌رسانی زمانی استفاده کنید که به پاسخ فوری نیاز ندارید یا می‌خواهید سرویس‌ها را از نظر زمانی جدا کنید.

- **[الگوی Circuit Breaker](../resilience/circuit-breaker.md):** یک الگوی تاب‌آوری که فراخوانی‌کنندگان RPI را از شکست‌های آبشاری محافظت می‌کند. وقتی یک سرویس پایین‌دست به طور مکرر شکست می‌خورد، circuit breaker باز می‌شود و درخواست‌ها را سریع خراب می‌کند به جای اینکه اجازه دهد مسدود شوند و مهلت بخورند. همراه ضروری هر پیاده‌سازی RPI.

- **[API Gateway](../architecture/api-gateway.md):** یک سرویس لبه‌ای که به عنوان نقطه ورود واحد برای کلاینت‌های خارجی عمل می‌کند. API Gateway فراخوانی‌های RPI را از کلاینت‌ها دریافت می‌کند، آن‌ها را به میکروسرویس صحیح هدایت می‌کند و می‌تواند پاسخ‌ها را از چندین سرویس تجمیع کند. همچنین نگرانی‌های مقطعی مانند احراز هویت، محدودیت نرخ و خاتمه SSL را مدیریت می‌کند.

- **[معماری میکروسرویس‌ها](../architecture/microservices.md):** سبک معماری گسترده‌تری که RPI در آن عمل می‌کند. درک تجزیه میکروسرویس‌ها، مالکیت داده‌ها و مرزهای سرویس، زمینه ضروری برای تصمیم‌گیری درباره مکان و نحوه استفاده از RPI است.

- **[معماری رویداد-محور](../event-driven/event-driven-architecture.md):** یک سبک معماری مکمل. بسیاری از سیستم‌ها از RPI برای پرس‌وجوها و دستورات همزمان و از رویدادها برای اطلاع‌رسانی‌ها و انتشار داده ناهمزمان استفاده می‌کنند. درک هر دو الگو به شما کمک می‌کند ابزار مناسب را برای هر تعامل انتخاب کنید.

- **[الگوی Saga](../distributed-transactions/saga.md):** وقتی یک تراکنش تجاری چندین سرویس را در بر می‌گیرد، الگوی Saga مراحل را هماهنگ می‌کند. هر مرحله ممکن است از RPI برای فراخوانی فردی سرویس استفاده کند، اما saga کلی به صورت ناهمزمان با تراکنش‌های جبرانی برای بازگشت مدیریت می‌شود.

---

## 8. کاربرد در دنیای واقعی

### Google (مبدأ gRPC)

Google gRPC را بر اساس چارچوب RPC داخلی خود به نام **Stubby** توسعه داد که بیش از 15 سال برای اتصال ناوگان عظیم میکروسرویس‌هایشان استفاده شده است. تقریباً تمام ارتباطات بین سرویسی در Google از نوعی RPI از طریق Stubby/gRPC استفاده می‌کند:

- **مقیاس:** میلیاردها فراخوانی RPC در ثانیه در سراسر زیرساخت Google
- **طراحی کلیدی:** قراردادهای سختگیرانه protobuf، مهلت‌ها در طول زنجیره فراخوانی، توازن بار خودکار
- **منبع‌باز** شده به عنوان gRPC در 2015، اکنون توسط Netflix، Square، Lyft، Docker، Cisco و بسیاری دیگر استفاده می‌شود

### Netflix

Netflix از رویکرد ترکیبی استفاده می‌کند و RPI و پیام‌رسانی را ترکیب می‌کند:

- **RPI (REST/gRPC):** برای عملیات بلادرنگ رو به کاربر مانند دریافت کاتالوگ محتوا، حل آدرس‌های پخش و احراز هویت کاربران استفاده می‌شود. این عملیات به پاسخ فوری نیاز دارند.
- **پیام‌رسانی:** برای پردازش پس‌زمینه، خطوط لوله داده و تحلیل‌ها استفاده می‌شود. Netflix زیرساخت پیام‌رسانی خود را بر روی Apache Kafka ساخته است.
- **تاب‌آوری:** Netflix الگوی [Circuit Breaker](../resilience/circuit-breaker.md) (Hystrix) را به طور خاص برای مدیریت شکست‌های RPI در مقیاس پیشگام شد.

### Uber

پلتفرم تطبیق سواری Uber برای عملیات حساس به تأخیر بر RPI تکیه دارد:

- **gRPC** برای ارتباط داخلی سرویس به سرویس (تطبیق سواران با رانندگان باید بلادرنگ انجام شود)
- **REST** برای APIهای عمومی (اپلیکیشن‌های موبایل راننده و سوار)
- **ترکیبی:** RPI برای دستورات همزمان (درخواست سواری، محاسبه کرایه)، پیام‌رسانی برای به‌روزرسانی‌های ناهمزمان (رویدادهای سفر، اطلاع‌رسانی‌ها)

### اکثر سیستم‌های میکروسرویسی

در عمل، اکثر سیستم‌های میکروسرویسی از RPI به عنوان مکانیزم ارتباطی اصلی خود برای عملیات همزمان استفاده می‌کنند:

- REST رایج‌ترین انتخاب برای APIهای عمومی و تیم‌هایی است که تازه با میکروسرویس‌ها شروع کرده‌اند
- gRPC به طور فزاینده‌ای برای ارتباط داخلی سرویس به سرویس که عملکرد اهمیت دارد پذیرفته می‌شود
- پیام‌رسانی RPI را برای عملیات ناهمزمان، انتشار رویداد و جداسازی تکمیل می‌کند

---

## 9. خلاصه

فراخوانی از راه دور (RPI) الگوی ارتباط همزمان بنیادی برای میکروسرویس‌ها است. یک مدل ساده، آشنا و مبتنی بر درخواست/پاسخ فراهم می‌کند که در آن کلاینت یک درخواست ارسال می‌کند و تا دریافت پاسخ مسدود می‌شود.

**نکات کلیدی:**

- **RPI همزمان است:** کلاینت تا پاسخ سرور مسدود می‌شود (درخواست/پاسخ)
- **دو فناوری غالب:** REST (HTTP/JSON) برای سادگی و جهانی بودن؛ gRPC (HTTP/2 + Protobuf) برای عملکرد و ایمنی نوع
- **کشف سرویس** برای یافتن نمونه‌های هدف لازم است (سمت کلاینت در مقابل سمت سرور)
- **مدیریت شکست حیاتی است:** مهلت‌ها، تلاش مجدد با backoff و [circuit breakerها](../resilience/circuit-breaker.md) همراهان ضروری هستند
- **وابستگی زمانی** اصلی‌ترین عیب است: هر دو سرویس باید همزمان در دسترس باشند
- **از RPI استفاده کنید وقتی** پاسخ فوری لازم است؛ از [پیام‌رسانی](../messaging/rabbitmq-vs-kafka.md) وقتی جداسازی و تاب‌آوری بیشتر از فوریت اهمیت دارند
- **اکثر سیستم‌های دنیای واقعی** از ترکیب استفاده می‌کنند: RPI برای پرس‌وجوها و دستورات همزمان، پیام‌رسانی برای رویدادها و جریان‌های کاری ناهمزمان

```
RPI Decision Summary:

Need immediate response?
│
├── Yes ──▶ Use RPI
│           ├── Public/external API? ──▶ REST
│           ├── Internal, high-perf?  ──▶ gRPC
│           └── Flexible queries?     ──▶ GraphQL
│
└── No  ──▶ Consider Messaging
            ├── Fire-and-forget?      ──▶ Async message
            ├── Event notification?   ──▶ Event streaming
            └── Long-running workflow?──▶ Saga + messaging
```

---

**منابع:**
- Chris Richardson, "Microservices Patterns" (2018) - فصل 3: ارتباط بین فرآیندی
- مستندات gRPC (grpc.io)
- Martin Fowler, مجموعه مقالات "Microservices"
- Sam Newman, "Building Microservices" (2021) - فصل 4: سبک‌های ارتباطی میکروسرویس
- Google Cloud Architecture: ارتباط میکروسرویس‌ها
